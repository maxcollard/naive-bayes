{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The naïve Bayes classifier\n",
    "\n",
    "Max Collard, May 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: The classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random variables: Quantifying observations\n",
    "\n",
    "Earlier, I drew lines in the sand of the multiverse that divided realities into *those where the mouse goes left* ($L$) and *those where the mouse goes right* ($R$). The direction the mouse goes is an **observation** that can be made about what happens in a given potential reality. Any observation we can make can be used to categorize realities. For example, let's call the observation of which direction the mouse goes $\\textrm{direction}$; this observation can take two possible values, $\\textrm{Left}$ and $\\textrm{Right}$.\n",
    "\n",
    "As we decided earlier, *every possible trial* can be assigned one of these two directions. In that case, it's common to use the notation\n",
    "\n",
    "$$ \\textrm{direction} = \\textrm{Left} $$\n",
    "\n",
    "as shorthand for \"all realities where we would observe $\\textrm{direction}$ equal to $\\textrm{Left}$\" (which we called $L$ before)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0127.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it makes sense to talk about things like\n",
    "\n",
    "$$ \\mathrm{Pr}(\\textrm{direction} = \\textrm{Left}) $$\n",
    "\n",
    "This is the *size* of the part of the multiverse where we would have seen this observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0128.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations are often numbers. For example, in the T maze example, we might have an electrode in a neuron that we use to measure the number of times a neuron fires before the mouse chooses a direction. We'll call this observation $N$. Then\n",
    "\n",
    "$$ N = 7 $$\n",
    "\n",
    "is shorthand for \"all realities where the neuron fires 7 times\", and\n",
    "\n",
    "$$ \\mathrm{Pr}(N = 7) $$\n",
    "\n",
    "is the size of the part of the multiverse where the neuron fired 7 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0129.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **random variable** is an *observation*, like $\\textrm{direction}$ or $N$, that we can make in *each possible reality*. Thought of in another way, a random variable is a *rule* that assigns to each reality a value, representing the observation that we *would make* in that particular reality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0133.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random variables are useful because, as we saw above, they give us a convenient way to *categorize* our potential worlds: just as in the examples above, we can draw a box around *all possible realities with the same observed result*. When we collect data, we are trying to **find ourselves** in the multiverse, by isolating only the set of possible worlds that match what we saw. When you see the neuron fire 7 times, you know that you are *in one of the realities where the neuron fired 7 times*.\n",
    "\n",
    "We can also use **conditional probabilities** with random variables. For example, we might be interested in finding the probability that our neuron fires 7 times *given* the knowledge that the mouse chooses to go left:\n",
    "\n",
    "$$ \\mathrm{Pr}(N = 7 \\mid \\textrm{direction} = \\textrm{Left}) $$\n",
    "\n",
    "Just like we saw before, this is the size of the set $N = 7$ *inside of* $\\textrm{direction} = \\textrm{Left}$—that is, where $\\textrm{direction} = \\textrm{Left}$ is now thought of as \"the entire multiverse\" we're thinking about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0132.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Let's say now that we are recording the activity from **five neurons** in the hippocampus of our mouse doing the T maze. In every possible reality, we can *observe* the number of action potentials each of those five neurons fires before the mouse makes its choice to go left or right; so, each one of those five counts is a *random variable*. We'll call these random variables $N_1, N_2, \\ldots, N_5$.\n",
    "\n",
    "When we run through a single trial, we get **actual numbers** for each of these random variables; this is the **data** that we collect from our experiment. Let's call the actual numbers we see for the five neurons $n_1, n_2, \\ldots, n_5$, respectively.\n",
    "\n",
    "The crucial aspect of the problem is this: the observation of these five counts *does not uniquely pinpoint our location in the multiverse*! There are many, many realities that have these exact same spike counts in the exact same neurons. We *do know*, though, that we live somewhere in the set\n",
    "\n",
    "$$ (N_1 = n_1) \\cap (N_2 = n_2) \\cap \\ldots \\cap (N_5 = n_5) = \\mathcal{D} $$\n",
    "\n",
    "This is the set of all realities where the observation of spikes in neuron 1, $N_1$, was the number we saw in our experiment, $n_1$; and so on for all five neurons (since intersection, $\\cap$, corresponds to \"**and**\"). That is, $\\mathcal{D}$ is the set of all realities that **match our observed data** of what happened with the neurons. Put in a Bayesian lens, $\\mathcal{D}$ is the *knowledge* we gained from our experiment; because of this, colloquially, we can just refer to $\\mathcal{D}$ as \"the data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0136.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we'd *really* like to do is to use our knowledge of the firing of these five neurons to **decide** whether the mouse went left or right. Since there are only two things (or \"classes\", $\\textrm{Left}$ and $\\textrm{Right}$) to decide between, making this decision based on the data is known as **classification**. When instead we want to decide a *numeric value* based on data, this problem is known as **regression**. The general theory of how we make these kinds of \"decisions\" based on data is called **decision theory**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0135.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we restrict ourself to only the \"region\" of the multiverse, $\\mathcal{D}$, that \"matches\" our data—and we know we live somewhere in there, because that's what we saw!— *some* of those realities will have the mouse going left. Similarly, *some* of those realities will have the mouse going right. What we want to know, then, is whether **more of the possible worlds that match our data have the mouse go left**. If this is true, then if we were pressed to make a choice of which direction the mouse went based on our data, the *best bet* is to say that the mouse **went to the left**; we'll be right more times than we're wrong. If, on the other hand, *more of the possible worlds that match our data have the mouse go to the right*, then we should say that the mouse *went to the right*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/2/IMG_0137.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we measure the \"size\" of the left-going and right-going possibilities *inside of* $\\mathcal{D}$? We already built the right tool for this job: **conditional probability**.\n",
    "\n",
    "For example, again going with the intuition that probability measures size, then the size of the left-going worlds *given* the data we observed (that is, inside of the region of the multiverse that matches the data) is\n",
    "\n",
    "$$ \\mathrm{Pr}(\\textrm{direction} = \\textrm{Left} \\mid \\mathcal{D}) $$\n",
    "\n",
    "(that is, \"the probability the mouse went left *given the data*\"). By the same token, we can also define\n",
    "\n",
    "$$ \\mathrm{Pr}(\\textrm{direction} = \\textrm{Right} \\mid \\mathcal{D}) $$\n",
    "\n",
    "Out of these two, the direction that gives us the **largest conditional probability** *given the data* is called the **maximum likelihood** estimate of the direction: it's the direction we should pick to get the *best prediction* (thought of as \"highest probability of being correct\") of which direction the mouse actually went."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
